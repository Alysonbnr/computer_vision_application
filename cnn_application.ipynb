{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_application.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Foram testadas duas situações. Um modelo de rede neural pre-treinado e uma cnn desenvolvida com todos os blocos de camadas convolunionais. "
      ],
      "metadata": {
        "id": "hiIgUlFiS-gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "io4vIkB1THBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kDTWq2sp9XRw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model,Model\n",
        "from keras.layers import Dense,Dropout, Activation, Flatten,Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras.callbacks import TensorBoard, EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função abaixo carrega os dados específicos para este dataset (BMW-10)"
      ],
      "metadata": {
        "id": "2D0nRhyVT1Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(datadir, img_size=200):\n",
        "\n",
        "    training_data = []\n",
        "    label = []\n",
        "    for category in range(3,6):\n",
        "        path = os.path.join(datadir, str(category))\n",
        "        class_num = category - 3\n",
        "        shufled_list  = list(os.listdir(path))\n",
        "        shuffle(shufled_list)\n",
        "\n",
        "        for img in shufled_list:\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
        "            training_data.append(img_array)\n",
        "            label.append(class_num)\n",
        "\n",
        "\n",
        "    return training_data , label"
      ],
      "metadata": {
        "id": "tm0UxUsUDbhC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "o bloco de funções seguintes gera o conjunto de validação, treino e teste."
      ],
      "metadata": {
        "id": "WJHYZB-9UF8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_normalized_array(X):\n",
        "    X = np.array(X)\n",
        "    X = (X / 255).astype(np.float16)\n",
        "    return X\n",
        "\n",
        "\n",
        "def train_val_test_split(X, y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
        "    X_train = generate_normalized_array(X_train)\n",
        "    X_val = generate_normalized_array(X_val)\n",
        "    X_test = generate_normalized_array(X_test)\n",
        "    return X_train,np.array(y_train),X_val,np.array(y_val),X_test,np.array(y_test)\n",
        "\n",
        "img_size = 100\n",
        "training_data, label = load_data('/content/dataset', img_size)\n",
        "X_train,y_train,X_val,y_val,X_test,y_test = train_val_test_split(training_data,label)\n",
        "print(\"[INFO] training data has \",len(X_train),\" samples\")\n",
        "print(\"[INFO] validation data has \",len(X_val),\" samples\")\n",
        "print(\"[INFO] test data has \",len(X_test),\" samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUURXsqRDxMH",
        "outputId": "1f69060a-5d30-4ec1-d087-47bd3e500ac3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training data has  84  samples\n",
            "[INFO] validation data has  22  samples\n",
            "[INFO] test data has  46  samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Bloco de funções seguintes gera um modelo de CNN básico criado desde o início."
      ],
      "metadata": {
        "id": "Gm5z2uk4UUlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_model(X_train,y_train,X_val,y_val,output_path,model_name='cnn_car_classifier'):\n",
        "    \n",
        "    model_file = os.path.join(output_path,model_name)\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(256, kernel_size=(3, 3), input_shape=X_train.shape[1:],padding='same'))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(256, kernel_size=(3,3),padding='same'))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),padding='same'))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(3))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='min')\n",
        "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=40, verbose=1,\n",
        "                                       epsilon=1e-4,\n",
        "                                       mode='min')\n",
        "    mcp_save = ModelCheckpoint(model_file +'.h5', save_best_only=True, monitor='val_loss',\n",
        "                               mode='min')\n",
        "    print(model.summary())\n",
        "\n",
        "    model.fit(X_train, y_train, batch_size=8, epochs=200, validation_data=(X_val, y_val), shuffle=True,callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
        "\n",
        "gen_model(X_train,y_train,X_val,y_val,'')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWEEPSHaEuf-",
        "outputId": "8f3ebd07-bfe6-4f86-b24c-56819ae9e38b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 100, 100, 256)     7168      \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 100, 100, 256)     0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 50, 50, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 50, 50, 256)       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 50, 50, 256)       590080    \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 50, 50, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 25, 25, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 25, 25, 256)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 25, 25, 128)       295040    \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 13, 13, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 21632)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 64899     \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 957,187\n",
            "Trainable params: 957,187\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 2s 96ms/step - loss: 1.2308 - sparse_categorical_accuracy: 0.3690 - val_loss: 1.2374 - val_sparse_categorical_accuracy: 0.3182 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.1264 - sparse_categorical_accuracy: 0.3571 - val_loss: 1.1061 - val_sparse_categorical_accuracy: 0.3182 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0803 - sparse_categorical_accuracy: 0.3929 - val_loss: 1.0951 - val_sparse_categorical_accuracy: 0.3636 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.0573 - sparse_categorical_accuracy: 0.3571 - val_loss: 1.0846 - val_sparse_categorical_accuracy: 0.3636 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.9993 - sparse_categorical_accuracy: 0.5119 - val_loss: 1.0672 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.9076 - sparse_categorical_accuracy: 0.5476 - val_loss: 1.0775 - val_sparse_categorical_accuracy: 0.3636 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.7273 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.0540 - val_sparse_categorical_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6156 - sparse_categorical_accuracy: 0.7262 - val_loss: 1.3113 - val_sparse_categorical_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4779 - sparse_categorical_accuracy: 0.7976 - val_loss: 1.2274 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4862 - sparse_categorical_accuracy: 0.7976 - val_loss: 1.6753 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.2556 - sparse_categorical_accuracy: 0.9048 - val_loss: 3.3399 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.3489 - sparse_categorical_accuracy: 0.8929 - val_loss: 1.7881 - val_sparse_categorical_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9167 - val_loss: 2.9093 - val_sparse_categorical_accuracy: 0.4091 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9286 - val_loss: 3.2072 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9643 - val_loss: 2.9273 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0481 - sparse_categorical_accuracy: 0.9881 - val_loss: 2.5080 - val_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9881 - val_loss: 3.8686 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9881 - val_loss: 3.2122 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0139 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.2475 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0046 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1269 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0044 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9395 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.1895 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0025 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9930 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0020 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6628 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.3744 - val_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5619 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 5.9018e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7958 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 8.4444e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7319 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 3.3129e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5847 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.5475e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6835 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 5.2833e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.6954 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.5732e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7901 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.9675e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8542 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 5.0284e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9977 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.6259e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0716 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 9.4274e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0007 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.5187e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7253 - val_sparse_categorical_accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 9.9097e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8937 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 3.3503e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0581 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.1607e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.1673 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.8260e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0958 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.9568e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7687 - val_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.3941e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.7194 - val_sparse_categorical_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 3.2757e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.8045 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4149e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9217 - val_sparse_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.4604e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9833 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8907e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.8907e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0193 - val_sparse_categorical_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 6.6321e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0197 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.2168e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0197 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 9.9418e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0188 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.9486e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0189 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4258e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0212 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.1561e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0231 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.7111e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0225 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 8.6610e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0221 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.8982e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0215 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 7.2945e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0214 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.4654e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0210 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 9.2383e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0205 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.3762e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0224 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.5122e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0239 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.1979e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0261 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 5.4379e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0274 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.2426e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0268 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 8.3522e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0255 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.5500e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0267 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 7.4696e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0273 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 9.4260e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0271 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.5914e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0288 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 8.1545e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0287 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 4.3742e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0281 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.0671e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0316 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.0900e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0321 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.4786e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0321 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 7.0844e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0301 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.3028e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0297 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.4352e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0311 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.7673e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0383 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 9.1221e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0381 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 8.3933e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0381 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.0969e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0406 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 7.6749e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9948 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 7.9453e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9791 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.1347e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9754 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 1.2141e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9772 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.5575e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9812 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 87/200\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 1.3694e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4461e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9827 - val_sparse_categorical_accuracy: 0.5455 - lr: 5.0000e-05\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.6316e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9829 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 3.4748e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9833 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.1223e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9838 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 9.2055e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9842 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 6.5622e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9843 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.7014e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9843 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 7.9837e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9862 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.6543e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9871 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 7.2919e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9876 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 6.0620e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9878 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 8.6612e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9879 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 9.7615e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9881 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 1.2880e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9883 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 1.5852e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9884 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 9.7964e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9886 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 1.0600e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9889 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 8.0065e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9890 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 8.0904e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9892 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 8.3865e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9895 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.9406e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.9898 - val_sparse_categorical_accuracy: 0.5455 - lr: 2.5000e-06\n",
            "Epoch 107: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O bloco de funções seguintes treina somente as camadas densas da mobileNet"
      ],
      "metadata": {
        "id": "1jl_matQUotL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mobile_network(X_train,y_train,X_val,y_val,output_path,model_name='mobile_car_classifier'):\n",
        "\n",
        "    model_file = os.path.join(output_path,model_name)\n",
        "    base_model = MobileNet(input_shape=(100,100,3), include_top=False, weights='imagenet')\n",
        "\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(3)(x)\n",
        "    x = Activation('softmax')(x)\n",
        "    model = Model(base_model.input, x)\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='min')\n",
        "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=40, verbose=1,\n",
        "                                       epsilon=1e-4,\n",
        "                                       mode='min')\n",
        "    mcp_save = ModelCheckpoint(model_file +'.h5', save_best_only=True, monitor='val_loss',\n",
        "                               mode='min')\n",
        "    model.fit(X_train, y_train, batch_size=8, epochs=200, validation_data=(X_val, y_val), shuffle=True,\n",
        "              callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
        "    \n",
        "generate_mobile_network(X_train,y_train,X_val,y_val,'')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUyZyF9jFW0c",
        "outputId": "86f9e743-ba6b-4e92-95c3-0be89793aa29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testes realizados com Mobile e a CNN criada"
      ],
      "metadata": {
        "id": "pw6SC6iIVTQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model_path,X_test,y_test):\n",
        "    model = load_model(model_path)\n",
        "    y_res = model.predict(X_test)\n",
        "    y_pred = [np.where(y==max(y))[0] for y in y_res]\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    print(classification_report(y_test,y_pred))\n",
        "print(\"RESULTADOS MOBILENET\")\n",
        "test_model('/content/mobile_car_classifier.h5',X_test,y_test)\n",
        "\n",
        "print(\"RESULTADOS CNN criada\")\n",
        "test_model('/content/mobile_car_classifier.h5',X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "MsL-JOoUFYtP",
        "outputId": "cc0a4c5a-e4dc-448f-deb3-8ac1696c6742"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTADOS MOBILENET\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.54      0.56        13\n",
            "           1       0.54      0.39      0.45        18\n",
            "           2       0.33      0.47      0.39        15\n",
            "\n",
            "    accuracy                           0.46        46\n",
            "   macro avg       0.49      0.46      0.47        46\n",
            "weighted avg       0.48      0.46      0.46        46\n",
            "\n",
            "RESULTADOS CNN criada\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.54      0.56        13\n",
            "           1       0.54      0.39      0.45        18\n",
            "           2       0.33      0.47      0.39        15\n",
            "\n",
            "    accuracy                           0.46        46\n",
            "   macro avg       0.49      0.46      0.47        46\n",
            "weighted avg       0.48      0.46      0.46        46\n",
            "\n"
          ]
        }
      ]
    }
  ]
}